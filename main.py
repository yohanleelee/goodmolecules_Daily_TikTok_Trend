import requests
import pandas as pd
from datetime import datetime
import time
import os

# 1. ì„¤ì • ì •ë³´
API_TOKEN = "apify_api_C2b8c0NEP4XXOVzqF7KTnaY7OMXYx926RYYD"
ACTOR_ID = "GdWCkxBtKWOsKjdch" 

def run_and_get_report(keyword):
    print(f"ğŸš€ [{keyword}] íŠ¸ë Œë“œ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ (ìµœì‹  24ì‹œê°„ ê¸°ì¤€)...")
    run_url = f"https://api.apify.com/v2/acts/{ACTOR_ID}/runs?token={API_TOKEN}"
    
    # ğŸ’¡ ì‹ ê·œ ì˜ìƒ ìˆ˜ì™€ ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ë°˜ì˜ì„ ìœ„í•œ ì„¤ì • ë³€ê²½
    # resultsPerPageë¥¼ 50ìœ¼ë¡œ ëŠ˜ë ¤ ë” ë„“ì€ ë²”ìœ„ë¥¼ ì²´í¬í•©ë‹ˆë‹¤.
    payload = {
        "searchQueries": [keyword],
        "resultsPerPage": 50,           
        "searchType": "video",
        "searchDateFilter": "past-24h", # ìµœê·¼ 24ì‹œê°„ ë°ì´í„°ë§Œ íƒ€ê²ŸíŒ… (ì‹ ê·œ ì—…ë¡œë“œ í™•ì¸ìš©)
        "searchSort": "latest"          # ê°€ì¥ ìµœì‹  ì˜ìƒë¶€í„° ìˆ˜ì§‘
    }
    
    response = requests.post(run_url, json=payload)
    run_res = response.json()
    
    if "data" not in run_res:
        print(f"âŒ ì‹¤í–‰ ì‹¤íŒ¨: {run_res}")
        return None
        
    dataset_id = run_res["data"]["defaultDatasetId"]
    
    print(f"âœ… ì‹¤í–‰ ì„±ê³µ! ë°ì´í„° ìˆ˜ì§‘ ëŒ€ê¸° ì¤‘ (50ì´ˆ)...")
    time.sleep(50) 
    
    items_url = f"https://api.apify.com/v2/datasets/{dataset_id}/items?token={API_TOKEN}"
    items = requests.get(items_url).json()
    
    if not items: 
        print(f"â„¹ï¸ ì§€ë‚œ 24ì‹œê°„ ë™ì•ˆ [{keyword}] ê´€ë ¨ ì‹ ê·œ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
        # ë°ì´í„°ê°€ ì—†ì„ ê²½ìš° 0ìœ¼ë¡œ ê¸°ë¡í•˜ì—¬ íŠ¸ë Œë“œ í•˜ë½ì„ í‘œì‹œí•©ë‹ˆë‹¤.
        items = []

    df = pd.DataFrame(items)
    
    # --- ë°ì´í„° ê³„ì‚° (ì„¸ë¶„í™” ì§€í‘œ) ---
    if not df.empty:
        plays = df['playCount'].mean() if 'playCount' in df.columns else 0
        likes = df['diggCount'].mean() if 'diggCount' in df.columns else 0
        comments = df['commentCount'].mean() if 'commentCount' in df.columns else 0
        shares = df['shareCount'].mean() if 'shareCount' in df.columns else 0
        new_clips = len(df) # 50ê°œ í•œë„ ë‚´ì—ì„œ ì‹¤ì œ ê²€ìƒ‰ëœ ì˜ìƒ ìˆ˜
    else:
        plays = likes = comments = shares = new_clips = 0

    report_data = {
        "Date": datetime.now().strftime("%Y-%m-%d"),
        "Keyword": keyword,
        "Score": round((plays * 0.01) + (likes * 0.5) + (comments * 2), 2),
        "Avg_Views": int(plays),
        "Avg_Likes": int(likes),
        "Avg_Comments": int(comments),
        "Avg_Shares": int(shares),
        "New_Clips": new_clips
    }
    
    # ğŸ’¾ CSV íŒŒì¼ì— ëˆ„ì  ì €ì¥
    file_name = "tiktok_trends_master.csv"
    df_new = pd.DataFrame([report_data])
    
    if not os.path.exists(file_name):
        df_new.to_csv(file_name, index=False, encoding='utf-8-sig')
        print(f"âœ… ìƒˆ íŒŒì¼ {file_name} ìƒì„± ë° ì²« ë°ì´í„° ì €ì¥ ì™„ë£Œ.")
    else:
        df_old = pd.read_csv(file_name)
        # ì˜¤ëŠ˜ ë‚ ì§œ ì¤‘ë³µ ì²´í¬ (ë¬¸ìì—´ ë³€í™˜ í›„ ë¹„êµ)
        if str(report_data["Date"]) not in df_old["Date"].astype(str).values:
            df_combined = pd.concat([df_old, df_new], ignore_index=True)
            df_combined.to_csv(file_name, index=False, encoding='utf-8-sig')
            print(f"âœ… {report_data['Date']} íŠ¸ë Œë“œ ë°ì´í„°ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            # ì¤‘ë³µ ë°ì´í„°ê°€ ìˆì„ ê²½ìš° ê¸°ì¡´ í–‰ì„ ì—…ë°ì´íŠ¸í•˜ê±°ë‚˜ ê±´ë„ˆëœë‹ˆë‹¤.
            print(f"â„¹ï¸ {report_data['Date']} ë°ì´í„°ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. (ì—…ë°ì´íŠ¸ ìƒëµ)")
            
    return report_data

# ì‹¤í–‰
report = run_and_get_report("goodmolecules")
